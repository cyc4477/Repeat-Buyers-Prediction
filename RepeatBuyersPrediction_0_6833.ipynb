{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "RepeatBuyersPrediction_0.6833.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp7uIANmxDox"
      },
      "source": [
        "## Load Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUdny5t2HGyb",
        "outputId": "be9883cb-3a1c-4ba5-ddba-f60f34cd2d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# 更改运行目录\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Repeat Buyers Prediction/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHmJU1EDHAuu",
        "outputId": "1002dbe5-94f0-4447-9674-1be62f098005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#导入分析库\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "!pip install catboost\n",
        "import catboost as cat\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "# LOCAL_QUICK = True\n",
        "LOCAL_QUICK = False\n",
        "sample_percent = 0.1\n",
        "\n",
        "MORE_FE = False\n",
        "# MORE_FE = True\n",
        "FE_V1 = False if MORE_FE else True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/61/2b8106c8870601671d99ca94d8b8d180f2b740b7cdb95c930147508abcf9/catboost-0.23-cp36-none-manylinux1_x86_64.whl (64.7MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcIL6KzTHx7S",
        "outputId": "d5450150-4599-450a-eb9f-ffd00c21e40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# 加载数据\n",
        "# 用户行为，使用format1进行加载\n",
        "user_log = pd.read_csv('./user_log_format1.csv', dtype={'time_stamp':'str'})\n",
        "\n",
        "user_info = pd.read_csv('./user_info_format1.csv')\n",
        "\n",
        "train_data1 = pd.read_csv('./train_format1.csv')\n",
        "\n",
        "sub_data = pd.read_csv('./test_format1.csv')\n",
        "data_train = pd.read_csv('./train_format2.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.3 s, sys: 6.29 s, total: 36.6 s\n",
            "Wall time: 53 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v7sOucbg44T",
        "outputId": "b41d2f9d-5f62-44f1-f9e5-4f98bf67ed03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "%%time\n",
        "# 采样测试\n",
        "if LOCAL_QUICK:\n",
        "    print('Local quick test: {}, rate is {}'.format(\n",
        "        LOCAL_QUICK, sample_percent))\n",
        "    data = user_log.sample(int(len(user_log) * sample_percent))\n",
        "    data1 = user_info.sample(int(len(user_info) * sample_percent))\n",
        "    data2 = train_data1.sample(int(len(train_data1) * sample_percent))\n",
        "    # submission = sub_data.sample(int(len(sub_data) * sample_percent))\n",
        "    submission = sub_data.copy()\n",
        "\n",
        "else:\n",
        "    print('All sample train')\n",
        "    data = user_log.copy()\n",
        "    data1 = user_info.copy()\n",
        "    data2 = train_data1.copy()\n",
        "    submission = sub_data.copy()\n",
        "    del user_log, user_info, train_data1, sub_data\n",
        "print('---data shape---')\n",
        "for df in [data, data1, data2, submission, data_train]:\n",
        "    print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All sample train\n",
            "---data shape---\n",
            "(54925330, 7)\n",
            "(424170, 3)\n",
            "(260864, 3)\n",
            "(261477, 3)\n",
            "(7030723, 6)\n",
            "CPU times: user 1.03 s, sys: 1.66 s, total: 2.68 s\n",
            "Wall time: 2.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT2QGDNkHAu4"
      },
      "source": [
        "data2['origin'] = 'train'\n",
        "submission['origin'] = 'test'\n",
        "matrix = pd.concat([data2, submission], ignore_index=True, sort=False)\n",
        "matrix.drop(['prob'], axis=1, inplace=True)\n",
        "# 连接user_info表，通过user_id关联\n",
        "matrix = matrix.merge(data1, on='user_id', how='left')\n",
        "# 使用merchant_id（原列名seller_id）\n",
        "data.rename(columns={'seller_id':'merchant_id'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emc8OvZvHAu8",
        "outputId": "5836054e-8a9d-4cdc-d7cc-db1865b4844e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# 格式化\n",
        "data['user_id'] = data['user_id'].astype('int32')\n",
        "data['merchant_id'] = data['merchant_id'].astype('int32')\n",
        "data['item_id'] = data['item_id'].astype('int32')\n",
        "data['cat_id'] = data['cat_id'].astype('int32')\n",
        "data['brand_id'].fillna(0, inplace=True)\n",
        "data['brand_id'] = data['brand_id'].astype('int32')\n",
        "data['time_stamp'] = pd.to_datetime(data['time_stamp'], format='%H%M')\n",
        "# 缺失值填充\n",
        "matrix['age_range'].fillna(0, inplace=True)\n",
        "matrix['gender'].fillna(2, inplace=True)\n",
        "\n",
        "# # gender用众数填充 表现更差\n",
        "# matrix['gender'].fillna(matrix['gender'].mode()[0],inplace=True)\n",
        "# # 年龄用中位数填充\n",
        "# matrix['age_range'].fillna(matrix['age_range'].median(),inplace=True)\n",
        "\n",
        "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
        "matrix['gender'] = matrix['gender'].astype('int8')\n",
        "matrix['label'] = matrix['label'].astype('str')\n",
        "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
        "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
        "\n",
        "del data1, data2\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.16 s, sys: 295 ms, total: 7.46 s\n",
            "Wall time: 7.46 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FbHkI6RHAu_",
        "outputId": "f53d20cc-9b15-4778-9f4f-9387fbed316e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "##### 特征处理\n",
        "##### User特征处理\n",
        "groups = data.groupby(['user_id'])\n",
        "# 用户交互行为数量 u1\n",
        "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "# 使用agg 基于列的聚合操作，统计唯一值个数 item_id, cat_id, merchant_id, brand_id\n",
        "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "# 时间间隔特征 u6 按照小时\n",
        "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
        "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
        "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
        "# 统计操作类型为0，1，2，3的个数\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(\n",
        "    columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
        "matrix = matrix.merge(temp, on='user_id', how='left')\n",
        "\n",
        "del temp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 44s, sys: 312 ms, total: 3min 44s\n",
            "Wall time: 3min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnvNCjc4HAvC",
        "outputId": "b8dfd4d9-f649-4e74-e695-4e0bf91ffe6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "##### 商家特征处理\n",
        "groups = data.groupby(['merchant_id'])\n",
        "# 商家被交互行为数量 m1\n",
        "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
        "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={\n",
        "    'user_id':'m2',\n",
        "    'item_id':'m3',\n",
        "    'cat_id':'m4',\n",
        "    'brand_id':'m5'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "# 统计商家被交互的action_type 唯一值\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(\n",
        "    columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
        "\n",
        "del temp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 10s, sys: 178 ms, total: 4min 11s\n",
            "Wall time: 4min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vABAeEfhHAvF"
      },
      "source": [
        "# 按照merchant_id 统计随机负采样的个数\n",
        "temp = data_train[data_train['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
        "matrix = matrix.merge(temp, on='merchant_id', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9FRm4FyHAvI",
        "outputId": "800ce225-0731-4d10-8c55-4b7cac22a4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%%time\n",
        "##### 用户+商户特征\n",
        "groups = data.groupby(['user_id', 'merchant_id'])\n",
        "temp = groups.size().reset_index().rename(columns={0:'um1'})\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={\n",
        "    'item_id':'um2',\n",
        "    'cat_id':'um3',\n",
        "    'brand_id':'um4'\n",
        "})\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={\n",
        "    0:'um5',\n",
        "    1:'um6',\n",
        "    2:'um7',\n",
        "    3:'um8'\n",
        "})\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "temp = groups['time_stamp'].agg([('frist', 'min'), ('last', 'max')]).reset_index()\n",
        "temp['um9'] = (temp['last'] - temp['frist']).dt.seconds/3600\n",
        "temp.drop(['frist', 'last'], axis=1, inplace=True)\n",
        "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
        "\n",
        "del temp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 11s, sys: 3.41 s, total: 5min 14s\n",
            "Wall time: 5min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq0Ss1SvHAvK"
      },
      "source": [
        "\n",
        "matrix['r1'] = matrix['u9']/matrix['u7'] # 用户购买点击比\n",
        "matrix['r2'] = matrix['m8']/matrix['m6'] # 商家购买点击比\n",
        "matrix['r3'] = matrix['um7']/matrix['um5'] #不同用户不同商家购买点击比"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1RSi-7_HAvN"
      },
      "source": [
        "matrix.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFr7DhmAHAvP",
        "outputId": "3f308416-f212-481f-e9c3-41fbe8a364a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
        "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
        "matrix = pd.concat([matrix, temp], axis=1)\n",
        "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
        "matrix = pd.concat([matrix, temp], axis=1)\n",
        "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
        "\n",
        "del temp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 401 ms, sys: 16 ms, total: 417 ms\n",
            "Wall time: 417 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1cqxyEpHAvS",
        "outputId": "c523e9a4-acf4-426e-9387-84f816b03e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "# train、test-setdata\n",
        "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
        "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
        "\n",
        "if not LOCAL_QUICK:\n",
        "    if FE_V1:\n",
        "        train_data.to_csv('train_data.csv')\n",
        "        test_data.to_csv('test_data.csv')\n",
        "    if MORE_FE:\n",
        "        train_data.to_csv('train_data_moreFE.csv')\n",
        "        test_data.to_csv('test_data_moreFE.csv')\n",
        "\n",
        "del matrix\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.3 s, sys: 140 ms, total: 10.5 s\n",
            "Wall time: 18.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5WhQfjOjNLu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhfwkYDcjNjh"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWOUo9DVPiGa"
      },
      "source": [
        "## Load FeatureData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50VkvAJcHAvV"
      },
      "source": [
        "# get data\n",
        "if not LOCAL_QUICK:\n",
        "    if FE_V1:\n",
        "        train_data = pd.read_csv('train_data.csv')\n",
        "        test_data = pd.read_csv('test_data.csv')\n",
        "    if MORE_FE:\n",
        "        train_data = pd.read_csv('train_data_moreFE.csv')\n",
        "        test_data = pd.read_csv('test_data_moreFE.csv')\n",
        "\n",
        "# FeatureSelect_QUICK = True # Feature Select\n",
        "FeatureSelect_QUICK = False\n",
        "if FeatureSelect_QUICK: # 使用部分样本进行快速特征选择\n",
        "    train_data = train_data.sample(int(len(train_data) * sample_percent))\n",
        "\n",
        "# train_data = train_data[train_col]\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "\n",
        "del train_data\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2, random_state=42) # test_size=.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqaIdRNDxRjj"
      },
      "source": [
        "### XGB Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3luWffkDRW4D"
      },
      "source": [
        "# get data\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "del train_data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2, random_state=42) # test_size=.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17s8JUMYHAvi",
        "outputId": "ea67e253-a58c-45bd-d9c7-ce7315cfc011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "def xgb_train(X_train, y_train, X_valid, y_valid, verbose=True):\n",
        "    model_xgb = xgb.XGBClassifier(\n",
        "        max_depth=10, # raw8\n",
        "        n_estimators=1000,\n",
        "        min_child_weight=300,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        eta=0.3,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    model_xgb.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        eval_metric='auc',\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        verbose=verbose,\n",
        "        early_stopping_rounds=10 # 早停法，如果auc在10epoch没有进步就stop\n",
        "    )\n",
        "    print(model_xgb.best_score)\n",
        "    return model_xgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
            "Wall time: 13.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ephCxUW5bUOt",
        "outputId": "1e6da369-bc25-46fc-cb58-ea7f482b20d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_xgb = xgb_train(X_train, y_train, X_valid, y_valid, verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.689278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvHurIDHAvj",
        "outputId": "6b5ebd6b-4f5c-4f59-9ce2-4f555f645961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "prob = model_xgb.predict_proba(test_data)\n",
        "\n",
        "submission['prob'] = pd.Series(prob[:,1])\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_xgb.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.44 s, sys: 11.2 ms, total: 4.45 s\n",
            "Wall time: 4.48 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmivfIenrLMR"
      },
      "source": [
        "### LGB Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNz-dghnpJPR"
      },
      "source": [
        "############DEF:lgb_train################\n",
        "def lgb_train(X_train, y_train, X_valid, y_valid, verbose=True):\n",
        "    model_lgb = lgb.LGBMClassifier(\n",
        "        max_depth=10, # 8\n",
        "        n_estimators=1000,\n",
        "        min_child_weight=200,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        eta=0.3,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    model_lgb.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        eval_metric='auc',\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        verbose=verbose,\n",
        "        early_stopping_rounds=10\n",
        "    )\n",
        "\n",
        "    print(model_lgb.best_score_['valid_1']['auc'])\n",
        "    return model_lgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UIZFG6wrCob",
        "outputId": "09e47aa8-08d5-4ab7-d108-b8445868a0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_lgb = lgb_train(X_train, y_train, X_valid, y_valid, verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6882175357469706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX4r_eZ5O5IC",
        "outputId": "dd4b540b-fd8a-400b-ee27-ca4357c91432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "prob = model_lgb.predict_proba(test_data)\n",
        "submission['prob'] = pd.Series(prob[:,1])\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_lgb.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.29 s, sys: 14.5 ms, total: 4.3 s\n",
            "Wall time: 5.55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE73pxHEtY_r"
      },
      "source": [
        "### Cat Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWUQDp2t_tr"
      },
      "source": [
        "def cat_train(X_train, y_train, X_valid, y_valid, verbose=True):\n",
        "    model_cat = cat.CatBoostClassifier(learning_rate=0.02, iterations=5000, eval_metric='AUC', od_wait=50,\n",
        "                                od_type='Iter', random_state=10, thread_count=8, l2_leaf_reg=1, verbose=verbose)\n",
        "    model_cat.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50,\n",
        "            use_best_model=True)\n",
        "\n",
        "    print(model_cat.best_score_['validation']['AUC'])\n",
        "    return model_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsn3fl0avds1",
        "outputId": "56e8515a-21bb-4169-bded-2945c60e4ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_cat = cat_train(X_train, y_train, X_valid, y_valid, verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6888438643692378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCfec6TrxK_A",
        "outputId": "bfae6027-a577-48b6-f163-a7180ffda7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "prob = model_cat.predict_proba(test_data)\n",
        "submission['prob'] = pd.Series(prob[:,1])\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_cat.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.36 s, sys: 18.5 ms, total: 1.38 s\n",
            "Wall time: 2.26 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvMQL3-Mb4cA"
      },
      "source": [
        "## StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdGoRvWOlbqv"
      },
      "source": [
        "# 构造训练集和测试集\n",
        "def get_train_testDF(train_df,label_df):\n",
        "    skv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    trainX = []\n",
        "    trainY = []\n",
        "    testX = []\n",
        "    testY = []\n",
        "    for train_index, test_index in skv.split(X=train_df, y=label_df):\n",
        "        train_x, train_y, test_x, test_y = train_df.iloc[train_index, :], label_df.iloc[train_index], \\\n",
        "                                            train_df.iloc[test_index, :], label_df.iloc[test_index]\n",
        "\n",
        "        trainX.append(train_x)\n",
        "        trainY.append(train_y)\n",
        "        testX.append(test_x)\n",
        "        testY.append(test_y)\n",
        "    return trainX, testX, trainY, testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo2UhAdaWYwr"
      },
      "source": [
        "### lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2lnyIEKQG8g"
      },
      "source": [
        "# get data\n",
        "if not LOCAL_QUICK:\n",
        "    if FE_V1:\n",
        "        train_data = pd.read_csv('train_data.csv')\n",
        "        test_data = pd.read_csv('test_data.csv')\n",
        "    if MORE_FE:\n",
        "        train_data = pd.read_csv('train_data_moreFE.csv')\n",
        "        test_data = pd.read_csv('test_data_moreFE.csv')\n",
        "\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "\n",
        "del train_data\n",
        "\n",
        "# Split Train&Valid Data\n",
        "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtYojZzeb5AP",
        "outputId": "1efc1976-0f77-48bc-910a-ac59ab88bc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\n",
        "# lightgbm模型\n",
        "\n",
        "pred_lgbms = []\n",
        "for i in range(5):\n",
        "    print('\\n============================LGB training use Data {}/5============================\\n'.format(i+1))\n",
        "    model_lgb = lgb.LGBMClassifier(\n",
        "        max_depth=10, # 8\n",
        "        n_estimators=1000,\n",
        "        min_child_weight=200,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        eta=0.3,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    model_lgb.fit(\n",
        "        X_train[i],\n",
        "        y_train[i],\n",
        "        eval_metric='auc',\n",
        "        eval_set=[(X_train[i], y_train[i]), (X_valid[i], y_valid[i])],\n",
        "        verbose=False,\n",
        "        early_stopping_rounds=10\n",
        "    )\n",
        "\n",
        "    print(model_lgb.best_score_['valid_1']['auc'])\n",
        "\n",
        "    pred = model_lgb.predict_proba(test_data)\n",
        "    pred = pd.DataFrame(pred[:,1])\n",
        "    pred_lgbms.append(pred)\n",
        "pred_lgbms = pd.concat(pred_lgbms, axis=1)\n",
        "print(pred_lgbms)\n",
        "\n",
        "submission['prob'] = pred_lgbms.mean(axis=1)\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_KFold_lgb.csv', index=False)\n",
        "\n",
        "####0.6784"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================LGB training use Data 1/5============================\n",
            "\n",
            "0.6814285066081079\n",
            "\n",
            "============================LGB training use Data 2/5============================\n",
            "\n",
            "0.678075817616207\n",
            "\n",
            "============================LGB training use Data 3/5============================\n",
            "\n",
            "0.6769034528266582\n",
            "\n",
            "============================LGB training use Data 4/5============================\n",
            "\n",
            "0.678130625463615\n",
            "\n",
            "============================LGB training use Data 5/5============================\n",
            "\n",
            "0.6776812517271715\n",
            "               0         0         0         0         0\n",
            "0       0.172597  0.139495  0.174839  0.202953  0.120382\n",
            "1       0.077612  0.068260  0.091190  0.073946  0.055343\n",
            "2       0.085269  0.091514  0.093136  0.093108  0.082051\n",
            "3       0.085579  0.094960  0.102522  0.106962  0.098253\n",
            "4       0.049972  0.054350  0.054020  0.068434  0.044841\n",
            "...          ...       ...       ...       ...       ...\n",
            "260859  0.049012  0.062446  0.071548  0.066920  0.082217\n",
            "260860  0.039762  0.029111  0.031687  0.033621  0.027339\n",
            "260861  0.019739  0.020501  0.021444  0.015976  0.015180\n",
            "260862  0.037017  0.034872  0.044972  0.033323  0.033951\n",
            "260863  0.028490  0.035417  0.025533  0.027674  0.028257\n",
            "\n",
            "[260864 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh8hsgKgWow2"
      },
      "source": [
        "### catgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH095k2_Y2ec"
      },
      "source": [
        "# get data\n",
        "if not LOCAL_QUICK:\n",
        "    if FE_V1:\n",
        "        train_data = pd.read_csv('train_data.csv')\n",
        "        test_data = pd.read_csv('test_data.csv')\n",
        "    if MORE_FE:\n",
        "        train_data = pd.read_csv('train_data_moreFE.csv')\n",
        "        test_data = pd.read_csv('test_data_moreFE.csv')\n",
        "\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "\n",
        "del train_data\n",
        "\n",
        "# Split Train&Valid Data\n",
        "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN_dhID6qOsD",
        "outputId": "172b1b75-e5ad-4f08-dbfd-d1ccb3b985dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\n",
        "# catgbm模型\n",
        "\n",
        "pred_cats = []\n",
        "for i in range(5):\n",
        "    print('\\n============================CAT training use Data {}/5============================\\n'.format(i+1))\n",
        "    model_cat = cat.CatBoostClassifier(learning_rate=0.02, iterations=5000, eval_metric='AUC', od_wait=50,\n",
        "                                od_type='Iter', random_state=10, thread_count=8, l2_leaf_reg=1, verbose=False)\n",
        "    model_cat.fit(X_train[i], y_train[i], eval_set=[(X_valid[i], y_valid[i])], early_stopping_rounds=50,\n",
        "            use_best_model=True)\n",
        "    # print(model_cat.evals_result_)\n",
        "    print(model_cat.best_score_['validation']['AUC'])\n",
        "\n",
        "    pred = model_cat.predict_proba(test_data)\n",
        "    pred = pd.DataFrame(pred[:,1])\n",
        "    pred_cats.append(pred)\n",
        "pred_cats = pd.concat(pred_cats, axis=1)\n",
        "\n",
        "submission['prob'] = pred_cats.mean(axis=1)\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_KFold_cat.csv', index=False)\n",
        "\n",
        "\n",
        "#### 0.68001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================CAT training use Data 1/5============================\n",
            "\n",
            "0.6824405044370522\n",
            "\n",
            "============================CAT training use Data 2/5============================\n",
            "\n",
            "0.6802216199760176\n",
            "\n",
            "============================CAT training use Data 3/5============================\n",
            "\n",
            "0.6778579794359316\n",
            "\n",
            "============================CAT training use Data 4/5============================\n",
            "\n",
            "0.6791038275100539\n",
            "\n",
            "============================CAT training use Data 5/5============================\n",
            "\n",
            "0.6804717208509453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49QqMtKjWtBX"
      },
      "source": [
        "### xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Gv2OW2ZPTG"
      },
      "source": [
        "# get data\n",
        "if not LOCAL_QUICK:\n",
        "    if FE_V1:\n",
        "        train_data = pd.read_csv('train_data.csv')\n",
        "        test_data = pd.read_csv('test_data.csv')\n",
        "    if MORE_FE:\n",
        "        train_data = pd.read_csv('train_data_moreFE.csv')\n",
        "        test_data = pd.read_csv('test_data_moreFE.csv')\n",
        "\n",
        "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
        "\n",
        "del train_data\n",
        "\n",
        "# Split Train&Valid Data\n",
        "X_train, X_valid, y_train, y_valid = get_train_testDF(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnCAP5aRt4y_",
        "outputId": "44d45321-4d6f-423b-8dbc-de3cf3f6370b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# 将训练数据集划分分别训练5个lgbm,xgboost和catboost 模型\n",
        "# xgboost模型\n",
        "\n",
        "pred_xgbs = []\n",
        "for i in range(5):\n",
        "    print('\\n============================XGB training use Data {}/5============================\\n'.format(i+1))\n",
        "    model_xgb = xgb.XGBClassifier(\n",
        "        max_depth=10, # raw8\n",
        "        n_estimators=1000,\n",
        "        min_child_weight=300,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        eta=0.3,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    model_xgb.fit(\n",
        "        X_train[i],\n",
        "        y_train[i],\n",
        "        eval_metric='auc',\n",
        "        eval_set=[(X_train[i], y_train[i]), (X_valid[i], y_valid[i])],\n",
        "        verbose=False,\n",
        "        early_stopping_rounds=10 # 早停法，如果auc在10epoch没有进步就stop\n",
        "    )\n",
        "\n",
        "    print(model_xgb.best_score)\n",
        "\n",
        "    pred = model_xgb.predict_proba(test_data)\n",
        "    pred = pd.DataFrame(pred[:,1])\n",
        "    pred_xgbs.append(pred)\n",
        "pred_xgbs = pd.concat(pred_xgbs, axis=1)\n",
        "\n",
        "# make submission\n",
        "submission['prob'] = pred_xgbs.mean(axis=1)\n",
        "# submission.drop(['origin'], axis=1, inplace=True)\n",
        "submission.to_csv('submission_KFold_xgb.csv', index=False)\n",
        "\n",
        "#### 0.6803"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================XGB training use Data 1/5============================\n",
            "\n",
            "0.682694\n",
            "\n",
            "============================XGB training use Data 2/5============================\n",
            "\n",
            "0.680635\n",
            "\n",
            "============================XGB training use Data 3/5============================\n",
            "\n",
            "0.677834\n",
            "\n",
            "============================XGB training use Data 4/5============================\n",
            "\n",
            "0.681198\n",
            "\n",
            "============================XGB training use Data 5/5============================\n",
            "\n",
            "0.67939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J04lvym978Tz"
      },
      "source": [
        "\"\"\"\n",
        "xgb:0.689278, ##KFold## 0.6784\n",
        "lgb:0.688217, ##KFold## 0.6800\n",
        "cat:0.688843, ##KFold## 0.6803\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU2TQEoRduwt"
      },
      "source": [
        "Blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt8eYmt-b_7-"
      },
      "source": [
        "lgb6812 = pd.read_csv(\"submission_lgb0.6812968.csv\")\n",
        "xgb6787 = pd.read_csv(\"submission_xgb0.6787.csv\")\n",
        "cat6777 = pd.read_csv(\"submission_cat-val0.6827785215-onling0.6777246.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8zZRxXcTNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f9cd2047-688c-4c77-8ec4-c7203b4e1a04"
      },
      "source": [
        "# 先构造一个矩阵\n",
        "df = np.array([lgb6812.prob, xgb6787.prob, cat6777.prob])\n",
        "# 计算协方差矩阵\n",
        "np.corrcoef(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.94866069, 0.9108549 ],\n",
              "       [0.94866069, 1.        , 0.9113983 ],\n",
              "       [0.9108549 , 0.9113983 , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JSxIMkk9570"
      },
      "source": [
        "sub = lgb6812.copy()\n",
        "\n",
        "sub.prob = 0.6*lgb6812.prob + 0.4*cat6777.prob # Online test score:0.6830807\n",
        "sub.to_csv('./sub_blended11.csv', index=False)\n",
        "####################################0.6833209################################\n",
        "sub.prob = 0.5*lgb6812.prob + 0.3*cat6777.prob + 0.2*xgb6787.prob# Online test 0.6833209\n",
        "sub.to_csv('./sub_blended12.csv', index=False)\n",
        "\n",
        "sub.prob = 0.45*lgb6812.prob + 0.3*cat6777.prob + 0.25*xgb6787.prob# Online test 0.6832934\n",
        "sub.to_csv('./sub_blended13.csv', index=False)\n",
        "####################################0.6833171################################\n",
        "sub.prob = 0.45*lgb6812.prob + 0.35*cat6777.prob + 0.2*xgb6787.prob# Online test 0.6833171\n",
        "sub.to_csv('./sub_blended14.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}